{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np    # linear algebra\n",
    "import urllib         # load data from the web\n",
    "import scipy.optimize # optimization routines\n",
    "import random         # random number generation\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "You will need the following files:\n",
    "Amazon Gift Card data : https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz \n",
    "The above is a TSV formatted dataset, including reviews from one of the smaller Amazon categories. \n",
    "Data can be read using the Python csv.reader library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "import gzip\n",
    "path = 'amazon_reviews_us_Gift_Card_v1_00.tsv.gz'\n",
    "f = gzip.open(path, 'rt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "# Read the header:\n",
    "header = f.readline().strip().split('\\t')\n",
    "for line in f:\n",
    "    # Separate by tabs\n",
    "    line = line.split('\\t')\n",
    "    # Convert to key-value pairs\n",
    "    d = dict(zip(header, line))\n",
    "    # Convert strings to integers for some fields:\n",
    "    d['star_rating'] = int(d['star_rating'])\n",
    "    d['helpful_votes'] = int(d['helpful_votes'])\n",
    "    d['total_votes'] = int(d['total_votes'])\n",
    "    dataset.append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression - Week 1\n",
    "First, let’s see how ratings can be predicted as a function of \n",
    "(a) whether a review is a ‘verified purchase’, and\n",
    "(b) the length of the review (in characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. What is the distribution of ratings in the dataset? That is, how many 1-star, 2-star, 3-star (etc.) reviews\n",
    "are there? You may write out the values or include a simple plot (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(dataset)\n",
    "df['verified_purchase'] = df['verified_purchase'].apply(lambda x: 1 if x == 'Y' else 0) # change to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      4793\n",
      "2      1569\n",
      "3      3156\n",
      "4      9859\n",
      "5    129709\n",
      "Name: star_rating, dtype: int64\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = df['star_rating'].value_counts().sort_index()\n",
    "print(dist);\n",
    "print(pd.DataFrame(dist).plot.bar(rot=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (CSE158 only) Repeat the above question, but generate the distribution (a) only for reviews that are\n",
    "‘verified,’ and (b) only for reviews that are not verified. Write out the values or generate a plot to show\n",
    "the difference between these distributions (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['customer_id', 'helpful_votes', 'marketplace', 'product_category',\n",
       "       'product_id', 'product_parent', 'product_title', 'review_body',\n",
       "       'review_date', 'review_headline', 'review_id', 'star_rating',\n",
       "       'total_votes', 'verified_purchase', 'vine'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      4000\n",
      "2      1344\n",
      "3      2784\n",
      "4      8940\n",
      "5    118974\n",
      "Name: star_rating, dtype: int64\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_verified = df[df['verified_purchase'] == 1]['star_rating'].value_counts().sort_index()\n",
    "print(dist_verified);\n",
    "print(pd.DataFrame(dist_verified).plot.bar(rot=0));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1      793\n",
      "2      225\n",
      "3      372\n",
      "4      919\n",
      "5    10735\n",
      "Name: star_rating, dtype: int64\n",
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist_verified = df[df['verified_purchase'] == 0]['star_rating'].value_counts().sort_index()\n",
    "print(dist_verified);\n",
    "print(pd.DataFrame(dist_verified).plot.bar(rot=0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Train a simple predictor to predict the star rating using two features:\n",
    "<img src=\"fig1.png\" style=\"height:50px\"> \n",
    "\n",
    "Report the values of θ0, θ1, and θ2. Briefly describe your interpretation of these values, i.e., what do θ0,\n",
    "θ1, and θ2 represent? Explain these in terms of the features and labels, e.g. if the coefficient of ‘review\n",
    "length’ is negative, what would that say about positive versus negative reviews (1 mark)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Our feature matrix, X, will be contain the 2 columns of the df with values 'review is verified' and 'review length'\n",
    "    * review length needs to be added to the df\n",
    "* θ0 is the y- intercept of the regression line and θ1 & θ2 are slopes coefficients for 'review is verified' and 'review length' respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_length'] = [len(x) for x in df['review_body']] \n",
    "# review header is included in the length calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = df[['verified_purchase', 'review_length']]\n",
    "y_1 = df['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model_1 = LinearRegression()\n",
    "model_1.fit(X_1, y_1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.05041483, -0.0012466 ])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regression coefficients\n",
    "model_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear regression model calcualted θ1 = 0.05041483 (representing the coefficient for 'review is verified') and our θ2 = -0.0012466 (representing the coefficient for 'review length'). This tells us for every additional increase in star rating, the θ1 ('review is verified') increases by 0.05041483 and the θ2 ('review length') decreases by -0.0012466 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.844618169673417"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear regression model calcualted θ0 = 4.844618169673417 (representing the intercept of our regression line. This tells us that if the slope, or θ1 and θ2 are 0, the star rating will still be 4.844618169673417. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Train another predictor that only uses one feature:\n",
    "    <img src=\"fig2.png\" style=\"height:50px\"> \n",
    "\n",
    "Report the values of θ0 and θ1. Note that coefficient you found here might be quite different (i.e., much\n",
    "larger or smaller) than the one from Question 3, even though these coefficients refer to the same feature.\n",
    "Provide an explanation as to why these coefficients might vary so significantly (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2 = df[['verified_purchase']]\n",
    "y_2 = df['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LinearRegression()\n",
    "model_2.fit(X_2, y_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16852426])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our linear regression model calcualted θ1 = 0.16852426 (representing the coefficient for 'review is verified'). This tells us for every additional increase in star rating, the θ1 ('review is verified') increases by 0.16852426. Although this coefficient is the same as the one from question 3, its value is quite different. \n",
    "\n",
    "Linear Regression relys on a Conditionally Indepnedence Assumption:\n",
    "if you know y, then knowing x1 provides no additional information about x2\n",
    "\n",
    "The problem with usign linear regression (Naive Bayes) for a classification is: we can only decompose the model into the contribution of individual features if the features are independent or conditionally independent! \n",
    "\n",
    "This is because in simple regression (non multipul regression) the beta coefficient is propotional to the correlation between y and x. However, in multiple regression, the betas are proportional to the partial correlation. This partial correlation is the correlation between y and the considered x (controlled for the other regressors).\n",
    " \n",
    "In other words, we have to make sure the columns are independent or conditionally independent if we want to use regression, and this get complicated the more features we use. \n",
    "\n",
    "This means we cant just do 'counting' and stick the classifications together into one big feature vector, then we would be 'double counting' the features' affect. How do we fix this? --> Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.577583563324113"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Split the data into two fractions – the first 90% for training, and the remaining 10% testing (based on\n",
    "the order they appear in the file). Train the same model as in Question 4 on the training set only. What\n",
    "is the model’s MSE on the training and on the test set (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_3 = df[['verified_purchase']]\n",
    "y_3 = df['star_rating'].values\n",
    "\n",
    "N = len(X_3)\n",
    "n_percent = int(np.around(N*.9))\n",
    "X_train = X_3[:n_percent]\n",
    "X_test = X_3[n_percent:]\n",
    "y_train = y_3[:n_percent]\n",
    "y_test = y_3[n_percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = LinearRegression()\n",
    "model_3.fit(X_train, y_train)\n",
    "\n",
    "predictionsTrain = model_3.predict(X_train)\n",
    "predictionsTest = model_3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(Y_pred, Y_true):\n",
    "    return np.square(np.subtract(Y_true,Y_pred)).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6557415620280949"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE for the training set:\n",
    "mse(predictionsTrain, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9713823241629701"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MSE for the testing set:\n",
    "mse(predictionsTest, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to note that we can still get a R^2 of 1 (MSE of 0) if we throw in enough random features! That is why we must use data that wasnt used on the model (test data) to get a more accurate representation of the R^2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. (CSE158 only) Using the test set from Question 5, report the Mean Absolute Error (MAE) and R2\n",
    "coefficient for your predictor (on the test set) (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(Y_pred, Y_true):\n",
    "    \"\"\" Mean Absolute Error \"\"\"\n",
    "    return np.mean(np.abs(np.subtract(Y_true, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6228362918842943"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mean Absolute Error:\n",
    "mae(predictionsTest, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mean Absolute Error (MAE) is proportional to the varience of the data. This means than an 'acceptable' number for MSE depends on the varience. Therefore, it is helpful to look at the R^2 value.\n",
    "* If R^2 = 0, the model is a trivial predictor\n",
    "* If R^2 = 1, the model is a perfect predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.049088114308448505"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "# R^2 value:\n",
    "r2_score(y_test, predictionsTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification - Week 2\n",
    "\n",
    "In this question we’ll alter the prediction from our regression task, so that we are now classifying whether a\n",
    "review is verified. Continue using the 90%/10% training and test sets you constructed previously, i.e., train on\n",
    "the training set and report the error/accuracy on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. First, let’s train a predictor that estimates whether a review is verified using the rating and the length:\n",
    " <img src=\"fig3.png\" style=\"height:50px\"> \n",
    "\n",
    "Train a logistic regressor to make the above prediction (you may use a logistic regression library with de-\n",
    "fault parameters, e.g. linear model.LogisticRegression() from sklearn). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_4 = df[['star_rating', 'review_length']]\n",
    "y_4 = df['verified_purchase']\n",
    "\n",
    "N = len(X_4)\n",
    "n_percent = int(np.around(N*.9))\n",
    "X_train = X_4[:n_percent]\n",
    "X_test = X_4[n_percent:]\n",
    "y_train = y_4[:n_percent]\n",
    "y_test = y_4[n_percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "mod = LogisticRegression(C=1.0)\n",
    "mod.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report the classification accuracy of this predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Predictions\n",
    "train_pred = mod.predict(X_train)\n",
    "test_pred = mod.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516161488183519"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification accuracy on training set:\n",
    "train_accuracy = np.sum(y_train == train_pred) / len(train_pred)\n",
    "train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5589241397813401"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification accuracy on testing set:\n",
    "test_accuracy = np.sum(y_test == test_pred) / len(test_pred)\n",
    "test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report also the proportion of labels that are positive (i.e., the proportion of reviews\n",
    "that are verified) and the proportion of predictions that are positive (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518248283983097"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for training set (actual): \n",
    "np.sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996571692614978"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for training set (prediction):\n",
    "np.sum(train_pred) / len(train_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this mean? This tells us that the proportion of positive labels in our training set is high, but our predictions are almost 100% positive labels. Since our training set is ~91% positive labels, our predictions would be incorrect ~10% of the time. This is a decent predictor for the training set but, we do not know for sure if our training set is a good representation of the actual population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5586558454624724"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for testing set (actual):\n",
    "np.sum(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9990609698839628"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for testing set (prediction):\n",
    "np.sum(test_pred) / len(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this mean? This tells us that the proportion of positive labels in our testing set is high, but our predictions are almost 100% positive labels. We also know, looking at the proportion of positive labels in our testing set, that the data was split well. However, since our training set is ~91% positive labels, our predictions would be incorrect ~10% of the time. This is a decent predictor for the testing set but, we do not know for sure if our testing set is a good representation of the actual population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Considering same prediction problem as above, can you come up with a more accurate predictor (e.g. using\n",
    "features from the text, timestamp, etc.)? Write down the feature vector you design, and report its\n",
    "train/test accuracy (1 mark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets try to find another predictor that estimates whether a review is verified using other features. Lets take a closer look at the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>marketplace</th>\n",
       "      <th>product_category</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>review_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24371595</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Gift Card</td>\n",
       "      <td>B004LLIL5A</td>\n",
       "      <td>346014806</td>\n",
       "      <td>Amazon eGift Card - Celebrate</td>\n",
       "      <td>Great birthday gift for a young adult.</td>\n",
       "      <td>2015-08-31\\n</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>R27ZP1F1CD0C3Y</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>42489718</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Gift Card</td>\n",
       "      <td>B004LLIKVU</td>\n",
       "      <td>473048287</td>\n",
       "      <td>Amazon.com eGift Cards</td>\n",
       "      <td>It's an Amazon gift card and with over 9823983...</td>\n",
       "      <td>2015-08-31\\n</td>\n",
       "      <td>Gift card for the greatest selection of items ...</td>\n",
       "      <td>RJ7RSBCHUDNNE</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>861463</td>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>Gift Card</td>\n",
       "      <td>B00IX1I3G6</td>\n",
       "      <td>926539283</td>\n",
       "      <td>Amazon.com Gift Card Balance Reload</td>\n",
       "      <td>Good</td>\n",
       "      <td>2015-08-31\\n</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>R1HVYBSKLQJI5S</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  customer_id  helpful_votes marketplace product_category  product_id  \\\n",
       "0    24371595              0          US        Gift Card  B004LLIL5A   \n",
       "1    42489718              0          US        Gift Card  B004LLIKVU   \n",
       "2      861463              0          US        Gift Card  B00IX1I3G6   \n",
       "\n",
       "  product_parent                        product_title  \\\n",
       "0      346014806        Amazon eGift Card - Celebrate   \n",
       "1      473048287               Amazon.com eGift Cards   \n",
       "2      926539283  Amazon.com Gift Card Balance Reload   \n",
       "\n",
       "                                         review_body   review_date  \\\n",
       "0             Great birthday gift for a young adult.  2015-08-31\\n   \n",
       "1  It's an Amazon gift card and with over 9823983...  2015-08-31\\n   \n",
       "2                                               Good  2015-08-31\\n   \n",
       "\n",
       "                                     review_headline       review_id  \\\n",
       "0                                         Five Stars  R27ZP1F1CD0C3Y   \n",
       "1  Gift card for the greatest selection of items ...   RJ7RSBCHUDNNE   \n",
       "2                                         Five Stars  R1HVYBSKLQJI5S   \n",
       "\n",
       "   star_rating  total_votes vine  review_length  \n",
       "0            5            0    N             38  \n",
       "1            5            0    N            101  \n",
       "2            5            0    N              4  "
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = df.loc[:, df.columns != 'verified_purchase']\n",
    "features.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then I check out the distributions of some of the columns I think will make useful predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "US    149086\n",
       "Name: marketplace, dtype: int64"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['marketplace'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gift Card    149086\n",
       "Name: product_category, dtype: int64"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['product_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    129709\n",
       "4      9859\n",
       "1      4793\n",
       "3      3156\n",
       "2      1569\n",
       "Name: star_rating, dtype: int64"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['star_rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "N    149086\n",
       "Name: vine, dtype: int64"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features['vine'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What has this told me? Features like marketplace, product category, and vine only actually have one value, so they are not very useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If I wanted to use the 'review_date' as a feature, I need to convert it to a more useful for, in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_helpful'] = df['helpful_votes'] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final feature vector design: ['star_rating', 'review_length', 'is_helpful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = df[['star_rating', 'review_length', 'is_helpful']]\n",
    "y_final = df['verified_purchase']\n",
    "\n",
    "N = len(X_final)\n",
    "n_percent = int(np.around(N*.9))\n",
    "X_train = X_final[:n_percent]\n",
    "X_test = X_final[n_percent:]\n",
    "y_train = y_final[:n_percent]\n",
    "y_test = y_final[n_percent:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_2 = LogisticRegression(C=1.0)\n",
    "mod_2.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Predictions\n",
    "train_pred = mod_2.predict(X_train)\n",
    "test_pred = mod_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9516012431340691"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification accuracy on training set:\n",
    "train_accuracy_final = np.sum(y_train == train_pred) / len(train_pred)\n",
    "train_accuracy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_accuracy_final > train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.559125360520491"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classification accuracy on testing set:\n",
    "test_accuracy_final = np.sum(y_test == test_pred) / len(test_pred)\n",
    "test_accuracy_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.559125360520491\n",
      "0.5589241397813401\n"
     ]
    }
   ],
   "source": [
    "print(test_accuracy_final)\n",
    "print(test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy_final > test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woohoo! Testing accuracy has improved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just out of curiousity, lets check distribution of labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9518248283983097"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for training set (actual):\n",
    "np.sum(y_train) / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9996571692614978"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for training set (prediction):\n",
    "np.sum(train_pred) / len(train_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5586558454624724"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for testing set (actual):\n",
    "np.sum(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9991280434636797"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of positive labels for testing set (prediction):\n",
    "np.sum(test_pred) / len(test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does this tell us?\n",
    "These proportions are similiar to the proportions on the previous model we designed. This is expected since the accuracy did improve, but not by that much. This also leads me to suspect that the predictor will not perform this well on unseen data, since the classes (or values of 'verified_purchase') in the training data is almost entirely positive, unless this is an accurate represent the actual population (this does not seem to be the case since the actual labels in the testing data are only ~55% positive). How can we improve this? Maybe try shuffling the data instead of just picking the first 90% for training. Maybe train on less data (e.g. increasing testing data to 20%). Or maybe try running the LogisticRegression() model with the classes 'balanced'. Or better yet, if it was possible, get more data!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

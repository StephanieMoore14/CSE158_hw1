{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instructions\n",
    "You will need the following files:\n",
    "Amazon Gift Card data : https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Gift_Card_v1_00.tsv.gz \n",
    "The above is a TSV formatted dataset, including reviews from one of the smaller Amazon categories. \n",
    "Data can be read using the Python csv.reader library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regession - Week 1\n",
    "First, let’s see how ratings can be predicted as a function of \n",
    "(a) whether a review is a ‘verified purchase’, and\n",
    "(b) the length of the review (in characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the distribution of ratings in the dataset? That is, how many 1-star, 2-star, 3-star (etc.) reviews\n",
    "are there? You may write out the values or include a simple plot (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. (CSE158 only) Repeat the above question, but generate the distribution (a) only for reviews that are\n",
    "‘verified,’ and (b) only for reviews that are not verified. Write out the values or generate a plot to show\n",
    "the difference between these distributions (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Train a simple predictor to predict the star rating using two features:\n",
    "<img src=\"fig1.png\" style=\"height:50px\"> \n",
    "\n",
    "Report the values of θ0, θ1, and θ2. Briefly describe your interpretation of these values, i.e., what do θ0,\n",
    "θ1, and θ2 represent? Explain these in terms of the features and labels, e.g. if the coefficient of ‘review\n",
    "length’ is negative, what would that say about positive versus negative reviews (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Train another predictor that only uses one feature:\n",
    "    <img src=\"fig2.png\" style=\"height:50px\"> \n",
    "\n",
    "Report the values of θ0 and θ1. Note that coefficient you found here might be quite different (i.e., much\n",
    "larger or smaller) than the one from Question 3, even though these coefficients refer to the same feature.\n",
    "Provide an explanation as to why these coefficients might vary so significantly (1 mark).1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Split the data into two fractions – the first 90% for training, and the remaining 10% testing (based on\n",
    "the order they appear in the file). Train the same model as in Question 4 on the training set only. What\n",
    "is the model’s MSE on the training and on the test set (1 mark)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. (CSE158 only) Using the test set from Question 5, report the Mean Absolute Error (MAE) and R2\n",
    "coefficient for your predictor (on the test set) (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. (CSE258 only) Repeat the above experiment, varying the size of the training and test fractions between\n",
    "5% and 95% for training (using the complement for testing). Show how the training and test error vary\n",
    "as a function of the training set size (again using a simple plot or table). Does the size of the training\n",
    "set make a significant difference in testing performance? Comment on why it might or might not make\n",
    "a significant difference in this instance (2 marks).\n",
    "1Hint: you should consider both of the features from Question 3 in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regession - Week 1\n",
    "\n",
    "In this question we’ll alter the prediction from our regression task, so that we are now classifying whether a\n",
    "review is verified. Continue using the 90%/10% training and test sets you constructed previously, i.e., train on\n",
    "the training set and report the error/accuracy on the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. First, let’s train a predictor that estimates whether a review is verified using the rating and the length:\n",
    "        <img src=\"fig3.png\" style=\"height:50px\"> \n",
    "\n",
    "Train a logistic regressor to make the above prediction (you may use a logistic regression library with de-\n",
    "fault parameters, e.g. linear model.LogisticRegression() from sklearn). Report the classification accuracy of this predictor. Report also the proportion of labels that are positive (i.e., the proportion of reviews\n",
    "that are verified) and the proportion of predictions that are positive (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Considering same prediction problem as above, can you come up with a more accurate predictor (e.g. using\n",
    "features from the text, timestamp, etc.)? Write down the feature vector you design, and report its\n",
    "train/test accuracy (1 mark)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
